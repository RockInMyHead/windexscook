import { AudioUtils } from '@/lib/audio-utils';
import { BrowserCompatibility } from '@/lib/browser-compatibility';

export class OpenAISTT {
  private static mediaRecorder: MediaRecorder | null = null;
  private static audioChunks: Blob[] = [];
  private static isRecording = false;

  /**
   * –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–¥–¥–µ—Ä–∂–∫—É –∑–∞–ø–∏—Å–∏ –∞—É–¥–∏–æ –≤ –±—Ä–∞—É–∑–µ—Ä–µ
   */
  static isSupported(): boolean {
    const caps = BrowserCompatibility.getCapabilities();
    return !!(caps.mediaRecorder && caps.getUserMedia);
  }

  /**
   * –ù–∞—á–∏–Ω–∞–µ—Ç –∑–∞–ø–∏—Å—å –∞—É–¥–∏–æ
   */
  static async startRecording(): Promise<void> {
    if (this.isRecording) {
      throw new Error('–ó–∞–ø–∏—Å—å —É–∂–µ –∏–¥–µ—Ç');
    }

    // –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–¥–µ—Ä–∂–∫—É
    if (!this.isSupported()) {
      throw new Error('–ë—Ä–∞—É–∑–µ—Ä –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∑–∞–ø–∏—Å—å –∞—É–¥–∏–æ');
    }

    try {
      console.log('üé§ [OpenAI STT] –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –¥–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É...');

      // –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –¥–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          sampleRate: 16000 // –û–ø—Ç–∏–º–∞–ª—å–Ω–æ –¥–ª—è Whisper
        }
      });

      console.log('‚úÖ [OpenAI STT] –î–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É –ø–æ–ª—É—á–µ–Ω');

      // –°–æ–∑–¥–∞–µ–º MediaRecorder
      this.mediaRecorder = new MediaRecorder(stream, {
        mimeType: 'audio/webm;codecs=opus' // –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è Whisper
      });

      this.audioChunks = [];
      this.isRecording = true;

      // –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º chunks
      this.mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          this.audioChunks.push(event.data);
          console.log(`üì¶ [OpenAI STT] –ü–æ–ª—É—á–µ–Ω –∞—É–¥–∏–æ chunk: ${event.data.size} bytes`);
        }
      };

      // –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Å—Ç–∞–Ω–æ–≤–∫—É
      this.mediaRecorder.onstop = () => {
        console.log('‚èπÔ∏è [OpenAI STT] –ó–∞–ø–∏—Å—å –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞');
        // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤—Å–µ tracks
        stream.getTracks().forEach(track => track.stop());
      };

      // –ù–∞—á–∏–Ω–∞–µ–º –∑–∞–ø–∏—Å—å
      this.mediaRecorder.start(100); // –°–æ—Ö—Ä–∞–Ω—è–µ–º chunks –∫–∞–∂–¥—ã–µ 100ms
      console.log('üé¨ [OpenAI STT] –ó–∞–ø–∏—Å—å –Ω–∞—á–∞—Ç–∞');

    } catch (error) {
      console.error('‚ùå [OpenAI STT] –û—à–∏–±–∫–∞ –ø—Ä–∏ –Ω–∞—á–∞–ª–µ –∑–∞–ø–∏—Å–∏:', error);
      this.isRecording = false;
      throw new Error('–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è.');
    }
  }

  /**
   * –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∑–∞–ø–∏—Å—å –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—é
   */
  static async stopRecording(): Promise<string> {
    return new Promise((resolve, reject) => {
      if (!this.isRecording || !this.mediaRecorder) {
        reject(new Error('–ó–∞–ø–∏—Å—å –Ω–µ –±—ã–ª–∞ –Ω–∞—á–∞—Ç–∞'));
        return;
      }

      console.log('‚èπÔ∏è [OpenAI STT] –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–ø–∏—Å—å...');

      // –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ–∫–æ–Ω—á–∞–Ω–∏–µ –∑–∞–ø–∏—Å–∏
      this.mediaRecorder!.onstop = async () => {
        try {
          console.log(`üì¶ [OpenAI STT] –í—Å–µ–≥–æ chunks: ${this.audioChunks.length}`);

          // –°–æ–∑–¥–∞–µ–º Blob –∏–∑ chunks
          const audioBlob = new Blob(this.audioChunks, { type: 'audio/webm' });
          console.log(`üéµ [OpenAI STT] –°–æ–∑–¥–∞–Ω –∞—É–¥–∏–æ —Ñ–∞–π–ª: ${audioBlob.size} bytes`);

          // –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ WAV –¥–ª—è –ª—É—á—à–µ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å Whisper
          const wavBlob = await this.convertToWav(audioBlob);
          console.log(`üéµ [OpenAI STT] –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –≤ WAV: ${wavBlob.size} bytes`);

          // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—é
          const transcription = await this.transcribeAudio(wavBlob);
          console.log(`‚úÖ [OpenAI STT] –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: "${transcription}"`);

          this.isRecording = false;
          this.mediaRecorder = null;
          this.audioChunks = [];

          resolve(transcription);

        } catch (error) {
          console.error('‚ùå [OpenAI STT] –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø–∏—Å–∏:', error);
          this.isRecording = false;
          this.mediaRecorder = null;
          this.audioChunks = [];
          reject(error);
        }
      };

      // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–ø–∏—Å—å
      this.mediaRecorder!.stop();
    });
  }

  /**
   * –û—Ç–º–µ–Ω—è–µ—Ç –∑–∞–ø–∏—Å—å –±–µ–∑ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
   */
  static cancelRecording(): void {
    if (this.mediaRecorder && this.isRecording) {
      console.log('üö´ [OpenAI STT] –û—Ç–º–µ–Ω–∞ –∑–∞–ø–∏—Å–∏');

      this.mediaRecorder.stop();
      this.mediaRecorder.stream.getTracks().forEach(track => track.stop());

      this.isRecording = false;
      this.mediaRecorder = null;
      this.audioChunks = [];
    }
  }

  /**
   * –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç—É—Å –∑–∞–ø–∏—Å–∏
   */
  static isCurrentlyRecording(): boolean {
    return this.isRecording;
  }

  /**
   * –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç WebM –≤ WAV –¥–ª—è –ª—É—á—à–µ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å Whisper
   */
  private static async convertToWav(webmBlob: Blob): Promise<Blob> {
    return new Promise((resolve, reject) => {
      const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
      const fileReader = new FileReader();

      fileReader.onload = async (event) => {
        try {
          const arrayBuffer = event.target!.result as ArrayBuffer;
          const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

          // –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ WAV
          const wavBlob = this.audioBufferToWav(audioBuffer);
          audioContext.close();
          resolve(wavBlob);
        } catch (error) {
          audioContext.close();
          reject(error);
        }
      };

      fileReader.onerror = () => reject(new Error('–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞'));
      fileReader.readAsArrayBuffer(webmBlob);
    });
  }

  /**
   * –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç AudioBuffer –≤ WAV Blob
   */
  private static audioBufferToWav(buffer: AudioBuffer): Blob {
    const length = buffer.length;
    const numberOfChannels = buffer.numberOfChannels;
    const sampleRate = buffer.sampleRate;
    const bytesPerSample = 2; // 16-bit
    const blockAlign = numberOfChannels * bytesPerSample;
    const byteRate = sampleRate * blockAlign;
    const dataSize = length * blockAlign;
    const bufferSize = 44 + dataSize;

    const arrayBuffer = new ArrayBuffer(bufferSize);
    const view = new DataView(arrayBuffer);

    // WAV header
    const writeString = (offset: number, string: string) => {
      for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i));
      }
    };

    writeString(0, 'RIFF');
    view.setUint32(4, bufferSize - 8, true);
    writeString(8, 'WAVE');
    writeString(12, 'fmt ');
    view.setUint32(16, 16, true);
    view.setUint16(20, 1, true);
    view.setUint16(22, numberOfChannels, true);
    view.setUint32(24, sampleRate, true);
    view.setUint32(28, byteRate, true);
    view.setUint16(32, blockAlign, true);
    view.setUint16(34, 16, true);
    writeString(36, 'data');
    view.setUint32(40, dataSize, true);

    // PCM data
    let offset = 44;
    for (let i = 0; i < length; i++) {
      for (let channel = 0; channel < numberOfChannels; channel++) {
        const sample = Math.max(-1, Math.min(1, buffer.getChannelData(channel)[i]));
        view.setInt16(offset, sample * 0x7FFF, true);
        offset += 2;
      }
    }

    return new Blob([arrayBuffer], { type: 'audio/wav' });
  }

  /**
   * –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∞—É–¥–∏–æ –Ω–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—é —á–µ—Ä–µ–∑ OpenAI API
   */
  private static async transcribeAudio(audioBlob: Blob): Promise<string> {
    console.log('üåê [OpenAI STT] –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∞—É–¥–∏–æ –Ω–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—é...');

    const formData = new FormData();
    formData.append('file', audioBlob, 'audio.wav');
    formData.append('model', 'whisper-1');
    formData.append('language', 'ru');
    formData.append('response_format', 'text');

    const response = await fetch('/api/openai/v1/audio/transcriptions', {
      method: 'POST',
      body: formData
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error('‚ùå [OpenAI STT] –û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏:', errorText);
      throw new Error(`–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏: ${response.status}`);
    }

    const transcription = await response.text();
    return transcription.trim();
  }

  /**
   * –ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –∞—É–¥–∏–æ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—é (—É–¥–æ–±–Ω—ã–π –º–µ—Ç–æ–¥)
   */
  static async recordAndTranscribe(): Promise<string> {
    try {
      console.log('üé§ [OpenAI STT] –ù–∞—á–∏–Ω–∞–µ–º –∑–∞–ø–∏—Å—å –∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—é...');
      AudioUtils.startProcessingSound();

      await this.startRecording();

      // –ñ–¥–µ–º –Ω–µ–º–Ω–æ–≥–æ –¥–ª—è –Ω–∞—á–∞–ª–∞ –∑–∞–ø–∏—Å–∏
      await new Promise(resolve => setTimeout(resolve, 500));

      // –ó–¥–µ—Å—å –Ω—É–∂–Ω–æ –≤–Ω–µ—à–Ω–µ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–∫–æ–π –∑–∞–ø–∏—Å–∏
      // –í —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏ —ç—Ç–æ –¥–µ–ª–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ UI

      return await this.stopRecording();

    } catch (error) {
      AudioUtils.stopProcessingSound();
      throw error;
    }
  }
}

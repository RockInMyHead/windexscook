# Система голосового взаимодействия с ИИ-психологом

## Обзор

Система реализует комплексное голосовое взаимодействие между пользователем и ИИ-психологом Марком. Включает распознавание речи, синтез ответов, управление прерываниями и адаптацию под различные устройства.

## Архитектура системы

### Основные компоненты

#### 1. Транскрибация речи (`useTranscription.ts`)
**Двойная система распознавания:**
- **Браузерное API (SpeechRecognition)** - основной метод для десктопов
- **OpenAI Whisper** - резервный метод и основной для мобильных устройств

**Особенности:**
- Автоматическое определение стратегии по устройству
- Фильтрация галлюцинаций и шумов
- Мониторинг уровня громкости для обнаружения речи
- Специальная логика для Safari (iOS)

#### 2. Запись аудио (`useAudioRecorder.ts`)
**Возможности:**
- MediaRecorder API для записи в реальном времени
- Поддержка различных форматов: WebM, MP4, WAV, AAC, OGG
- Автоматический выбор оптимального MIME-типа для устройства
- Мониторинг уровня громкости в реальном времени

**Мобильная оптимизация:**
- Специальные audio constraints для мобильных устройств
- Уменьшенная sample rate для экономии трафика
- Моно-аудио для мобильных устройств

#### 3. Синтез речи (`useTTS.ts`)
**Возможности:**
- OpenAI TTS API (модели tts-1/tts-1-hd)
- Очередь воспроизведения с управлением прерыванием
- Генерация аудио в формате MP3 для лучшей совместимости
- Дедупликация TTS для предотвращения повторных синтезов

**Управление прерыванием:**
- Пользователь может прервать ответ психолога голосом
- Автоматическое определение прерываний по уровню громкости
- Специальная логика для Safari

#### 4. Серверные обработчики (`server.js`)
```
/api/audio/transcriptions - прокси для OpenAI Whisper API
/api/audio/speech - прокси для OpenAI TTS API
```

**Безопасность:**
- API-ключ не раскрывается в браузере
- Централизованная обработка ошибок
- Кеширование и оптимизация запросов

### Процесс работы

#### 1. Инициализация
```javascript
// Получение доступа к микрофону
const stream = await navigator.mediaDevices.getUserMedia({
  audio: {
    echoCancellation: true,
    noiseSuppression: true,
    autoGainControl: true,
    sampleRate: 44100
  }
});
```

#### 2. Определение стратегии распознавания
- **iOS/Safari**: OpenAI Whisper (браузерное API имеет ограничения)
- **Android**: Гибридный режим - OpenAI + браузерное API с таймером
- **Десктоп (Chrome/Edge/Opera)**: Преимущественно браузерное API, OpenAI как fallback
- **Firefox**: Только OpenAI (нет поддержки SpeechRecognition)

#### 3. Запись и мониторинг аудио
- Непрерывная запись с помощью MediaRecorder
- Мониторинг уровня громкости через AnalyserNode для обнаружения речи
- Для Safari: специальная логика обнаружения речи с учетом особенностей браузера

#### 4. Транскрибация
**Браузерное API:**
```javascript
const recognition = new SpeechRecognition();
recognition.lang = "ru-RU";
recognition.continuous = true;
recognition.interimResults = true;
recognition.maxAlternatives = 1;
```

**OpenAI Whisper:**
```javascript
// Отправка на сервер
const formData = new FormData();
formData.append('file', audioBlob, 'voice.webm');
formData.append('model', 'whisper-1');
formData.append('language', 'ru');
formData.append('prompt', 'Разговор с психологом...');
```

#### 5. Фильтрация результатов
Система фильтрует галлюцинации и шум:
- Удаляет шаблонные фразы ("продолжение следует", "до свидания")
- Отсеивает слишком короткие/длинные ответы
- Фильтрует бессмысленные звуки ("ммм", "эээ", "ааа")
- Проверяет уровень громкости аудио

#### 6. Синтез ответа
```javascript
const response = await fetch('/api/audio/speech', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    model: 'tts-1',
    voice: 'onyx',
    input: text,
    response_format: 'mp3',
    speed: 1.0
  })
});
```

## Особенности реализации

### Мобильная оптимизация
- На Android: таймер отправляет аудио на OpenAI каждые 3 секунды
- Специальные настройки аудио-constraints для мобильных устройств
- Увеличенные таймауты для медленных соединений

### Предотвращение эхо
- В Chrome: временно отключает распознавание во время воспроизведения TTS
- Мониторинг активного воспроизведения через isTTSActiveRef

### Обработка прерываний
- Пользователь может прервать ответ психолога голосом
- Safari имеет специальную логику обнаружения прерываний
- Автоматическое определение прерываний по уровню громкости

### Повторные попытки и fallback
- Автоматические повторные попытки при сетевых ошибках
- Переключение между браузерным API и OpenAI при сбоях
- Кастомные таймауты для разных устройств

## Архитектурные решения

### Почему двойная система распознавания
- **Браузерное API быстрее** (нет задержек сети)
- **OpenAI Whisper точнее** и поддерживает все языки
- **Fallback обеспечивает надежность**

### Почему серверные прокси
- **Безопасность**: API-ключ не раскрывается в браузере
- **Кеширование и оптимизация** запросов
- **Централизованная обработка ошибок**

### Почему WebRTC-подход
- **Низкая латентность** для реального времени
- **Поддержка всех современных браузеров**
- **Гибкая обработка аудио-потоков**

## API интерфейсы

### useAudioRecorder
```typescript
interface UseAudioRecorderProps {
  onRecordingComplete?: (blob: Blob) => void;
  onError?: (error: string) => void;
  onVolumeChange?: (volume: number) => void;
  mimeType?: string;
  echoCancellation?: boolean;
  noiseSuppression?: boolean;
  autoGainControl?: boolean;
  sampleRate?: number;
  channelCount?: number;
}
```

### useTranscription
```typescript
interface UseTranscriptionProps {
  transcriptionService?: TranscriptionService;
  onTranscriptionComplete: (text: string, source: 'browser' | 'openai' | 'manual') => void;
  onSpeechStart?: () => void;
  onInterruption?: () => void;
  isTTSActiveRef: React.MutableRefObject<boolean>;
  onError?: (error: string) => void;
}
```

### useTTS
```typescript
interface UseTTSProps {
  ttsService: TTSService;
  onPlaybackStatusChange?: (isPlaying: boolean) => void;
}
```

## Установка и настройка

1. **Установите зависимости:**
```bash
npm install
```

2. **Настройте переменные окружения:**
```env
VITE_OPENAI_API_KEY=sk-your-openai-api-key
```

3. **Запустите проект:**
```bash
npm run dev    # Frontend
npm run server # Backend
```

## Тестирование

### Запуск тестов
```bash
npm run test:e2e  # E2E тесты голосового взаимодействия
npm run test:frontend  # Тесты компонентов
npm run test:backend   # Тесты API
```

### Ручное тестирование
1. Откройте приложение в браузере
2. Разрешите доступ к микрофону
3. Начните аудио звонок
4. Говорите с психологом
5. Проверьте логи в debug режиме

## Мониторинг и отладка

### Debug логи
- Включите debug режим в интерфейсе
- Просматривайте логи в реальном времени
- Анализируйте сетевые запросы

### Метрики производительности
- Время отклика TTS
- Качество распознавания речи
- Уровень успешных транзакций
- Статистика fallback'ов

## Безопасность

- API ключи хранятся только на сервере
- Валидация всех входных данных
- Защита от XSS и CSRF атак
- Шифрование чувствительных данных

## Производительность

- Оптимизация размера аудио файлов
- Кеширование часто используемых ответов
- Асинхронная обработка запросов
- Минификация и компрессия ресурсов

## Заключение

Система голосового взаимодействия обеспечивает надежное и естественное общение с ИИ-психологом. Автоматически адаптируется под возможности устройства пользователя, обеспечивает высокое качество распознавания и синтеза речи, и предоставляет богатый пользовательский интерфейс с визуальными индикаторами состояния.

Основные преимущества:
- **Надежность**: двойная система распознавания с автоматическим fallback
- **Производительность**: оптимизация для мобильных и десктоп устройств
- **Безопасность**: серверная обработка API ключей
- **Удобство**: интуитивный интерфейс с визуальными индикаторами
- **Масштабируемость**: модульная архитектура для легкого расширения
